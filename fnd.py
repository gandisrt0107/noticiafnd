"""Salinan Fake News Detection with Machine Learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1snUKyT-iJHTCkDBPMNwv-ixRGtbibddK

# **Kelompok 4**

---

1. M. Yusuf
2. Gandis Ratna Cendani Karmana
3. Ganjar Arih Nurul Inas
4. Raden Roro Fara Diba
5. Rhena Yuni Junita
"""
import string
import re

import pandas as pd
import seaborn as sns
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt

from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import classification_report, confusion_matrix

from nltk.corpus import stopwords
stop = stopwords.words('indonesian')

"""## *Load Dataset*"""

fake = pd.read_csv("./dataset/Fake - Fake.csv")
true = pd.read_csv("./dataset/True - True.csv")

fake.shape, true.shape

"""## *Preprocessing*"""

# Membuat tanda untuk melacak fake dan real news
fake['target'] = 0
true['target'] = 1

# Menggabungkan data frame
data = pd.concat([fake, true], ignore_index=True, sort=False)
data.head()

# Mengacak data untuk mencegah bias
data = shuffle(data)
data = data.reset_index(drop=True)
data.head()

# Menghapus judul, subjek dan tanggal karena tidak dibutuhkan
data.drop(["title", "subject", "date"],axis=1,inplace=True)
data.head()

# Mengubah ke huruf kecil
data['text'] = data['text'].apply(lambda x: x.lower())
data.head()

# Menghapus tanda baca
def punctuation_removal(text):
    all_list = [char for char in text if char not in string.punctuation]
    clean_str = ''.join(all_list)
    return clean_str

data['text'] = data['text'].apply(punctuation_removal)
data.head()

# Menghapus Stopwords
data['text'] = data['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))
data.head()

# restructure datatype
texts = ' '.join(data['text'])
string = texts.split(" ")

"""## *Pembagian Dataset*

### Membuat fungsi text
"""

def wordopt(text):
    text = text.lower()
    text = re.sub('\[.*?\]', '', text)
    text = re.sub("\\W"," ",text) 
    text = re.sub('https?://\S+|www\.\S+', '', text)
    text = re.sub('<.*?>+', '', text)
    # text = re.sub('[%s]' % re.escape(string.punctuation), '', text)
    text = re.sub('\n', '', text)
    text = re.sub('\w*\d\w*', '', text)    
    return text

data["text"] = data["text"].apply(wordopt)

"""### Split Data"""

X_train,X_test,y_train,y_test = train_test_split(data['text'], data['target'], test_size=0.2, random_state=0)

"""## *Modeling dan Evaluasi*

### **Model dan Evaluasi Machine Learning**
"""

vectorization = TfidfVectorizer()
Xv_train = vectorization.fit_transform(X_train)
Xv_test = vectorization.transform(X_test)

"""#### Logistic Regression"""

from sklearn.linear_model import LogisticRegression

LR = LogisticRegression()
LR.fit(Xv_train,y_train)
pred_lr=LR.predict(Xv_test)
LR.score(Xv_test, y_test)

# print(classification_report(y_test, pred_lr))

cm_LR_text = confusion_matrix(pred_lr,y_test)
sns.heatmap(cm_LR_text, annot=True, fmt='d',cmap='magma')
plt.title('Logistic Regression Confusion Matrix');

"""#### Decision Tree Classification"""

from sklearn.tree import DecisionTreeClassifier

DT = DecisionTreeClassifier()
DT.fit(Xv_train, y_train)
pred_dt = DT.predict(Xv_test)
DT.score(Xv_test, y_test)

# print(classification_report(y_test, pred_dt))

cm_DT_text = confusion_matrix(pred_dt,y_test)
sns.heatmap(cm_DT_text, annot=True, fmt='d',cmap='magma')
plt.title('Decision Tree Confusion Matrix');

"""#### Random Forest Classifier"""

from sklearn.ensemble import RandomForestClassifier

RFC = RandomForestClassifier(random_state=0)
RFC.fit(Xv_train, y_train)
pred_rfc = RFC.predict(Xv_test)
RFC.score(Xv_test, y_test)

# print(classification_report(y_test, pred_rfc))

cm_RFC_text = confusion_matrix(pred_rfc,y_test)
sns.heatmap(cm_RFC_text, annot=True, fmt='d',cmap='magma')
plt.title('Random Forest Confusion Matrix');

"""#### Gradient Boosting Classifier"""

from sklearn.ensemble import GradientBoostingClassifier

GBC = GradientBoostingClassifier(random_state=0)
GBC.fit(Xv_train, y_train)
pred_gbc = GBC.predict(Xv_test)
GBC.score(Xv_test, y_test)

# print(classification_report(y_test, pred_gbc))

cm_GBC_text = confusion_matrix(pred_gbc,y_test)
sns.heatmap(cm_GBC_text, annot=True, fmt='d',cmap='magma')
plt.title('Gradient Boosting Confusion Matrix')

"""#### *Using model in external script*"""
    
def prediction(news):
    testing_news = {"text":[news]}
    new_def_test = pd.DataFrame(testing_news)
    new_def_test["text"] = new_def_test["text"].apply(wordopt) 
    new_X_test = new_def_test["text"]
    new_Xv_test = vectorization.transform(new_X_test)
    pred = {}
    pred['LR'] = LR.predict(new_Xv_test)
    pred['DT'] = DT.predict(new_Xv_test)
    pred['GBC'] = GBC.predict(new_Xv_test)
    pred['RFC'] = RFC.predict(new_Xv_test)
    return pred
